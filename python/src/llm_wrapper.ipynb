{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "994da32c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import AutoModelForCausalLM, AutoTokenizer\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e36082ef",
   "metadata": {},
   "outputs": [],
   "source": [
    "class LLMWrapper:\n",
    "    def __init__(self):\n",
    "        print(f\"Loading LLM: {Config.MODEL_ID}...\")\n",
    "        self.tokenizer = AutoTokenizer.from_pretrained(Config.MODEL_ID)\n",
    "        \n",
    "        device = \"cuda\" if torch.cuda.is_available() else \"cpu\"\n",
    "        self.model = AutoModelForCausalLM.from_pretrained(\n",
    "            Config.MODEL_ID,\n",
    "            torch_dtype=torch.float16 if device == \"cuda\" else torch.float32,\n",
    "            device_map=\"auto\" if device == \"cuda\" else None\n",
    "        )\n",
    "        # Lưu ý: Nếu dùng device_map=\"auto\", model đã tự vào đúng device, lệnh này thừa nhưng ko sao\n",
    "        # self.model.to(device) \n",
    "        print(\"LLM Loaded successfully.\")\n",
    "    \n",
    "    def generate(self, prompt, max_new_tokens=512):\n",
    "        print(\"\\n\" + \"=\"*50)\n",
    "        print(\"BẮT ĐẦU QUÁ TRÌNH GENERATE\")\n",
    "        print(\"=\"*50)\n",
    "\n",
    "        # --- BƯỚC 1: TẠO MESSAGES ---\n",
    "        # Đây là cấu trúc chuẩn để model hiểu đâu là vai của AI, đâu là người dùng\n",
    "        messages = [\n",
    "            {\"role\": \"system\", \"content\": \"Bạn là nhân viên hỗ trợ đặt món tại nhà hàng Hòa Viên.\"},\n",
    "            {\"role\": \"user\", \"content\": prompt}\n",
    "        ]\n",
    "        print(f\"\\n[1] Messages (List of Dicts):\\n{messages}\")\n",
    "\n",
    "        # --- BƯỚC 2: APPLY CHAT TEMPLATE ---\n",
    "        # Biến đổi list trên thành 1 chuỗi văn bản duy nhất kèm các ký tự đặc biệt\n",
    "        # Ví dụ model sẽ thêm <|im_start|>system...<|im_end|> tùy loại model\n",
    "        text = self.tokenizer.apply_chat_template(\n",
    "            messages,\n",
    "            tokenize=False,\n",
    "            add_generation_prompt=True\n",
    "        )\n",
    "        print(f\"\\n[2] Text sau khi Template (String raw):\\n{text!r}\") \n",
    "        # (Dùng !r để in ra cả các ký tự xuống dòng \\n giúp dễ nhìn)\n",
    "\n",
    "        # --- BƯỚC 3: TOKENIZATION ---\n",
    "        # Biến đổi chữ thành số (Tensors)\n",
    "        model_inputs = self.tokenizer([text], return_tensors=\"pt\").to(self.model.device)\n",
    "        input_ids = model_inputs.input_ids\n",
    "        print(f\"\\n[3] Input Ids (Tensor số hóa câu hỏi):\\n{input_ids}\")\n",
    "        print(f\" -> Kích thước Input: {input_ids.shape} (Dài {input_ids.shape[1]} tokens)\")\n",
    "\n",
    "        # --- BƯỚC 4: MODEL GENERATE ---\n",
    "        # Máy tính toán và sinh ra các số tiếp theo\n",
    "        print(f\"\\n[4] Đang suy nghĩ (Generate)...\")\n",
    "        generated_ids_raw = self.model.generate(\n",
    "            model_inputs.input_ids,\n",
    "            max_new_tokens=max_new_tokens\n",
    "        )\n",
    "        # generated_ids_raw lúc này chứa cả [Input cũ + Output mới]\n",
    "        print(f\" -> Generated Ids Raw (Gồm cả Input + Output):\\n{generated_ids_raw}\")\n",
    "        print(f\" -> Kích thước Raw: {generated_ids_raw.shape} (Dài {generated_ids_raw.shape[1]} tokens)\")\n",
    "\n",
    "        # --- BƯỚC 5: SLICING (CẮT BỎ INPUT) ---\n",
    "        # Chỉ giữ lại phần mới sinh ra\n",
    "        generated_ids_trimmed = [\n",
    "            output_ids[len(input_ids):] for input_ids, output_ids in zip(model_inputs.input_ids, generated_ids_raw)\n",
    "        ]\n",
    "        # Vì batch_size=1 nên ta lấy phần tử đầu tiên xem cho dễ\n",
    "        print(f\"\\n[5] Sliced Ids (Chỉ còn phần trả lời):\\n{generated_ids_trimmed[0]}\")\n",
    "        \n",
    "        # --- BƯỚC 6: DECODE ---\n",
    "        # Dịch số ngược lại thành chữ\n",
    "        response_text = self.tokenizer.batch_decode(generated_ids_trimmed, skip_special_tokens=True)[0]\n",
    "        print(f\"\\n[6] Kết quả cuối cùng (Decoded Text):\\n{response_text}\")\n",
    "        \n",
    "        print(\"\\n\" + \"=\"*50 + \"\\n\")\n",
    "        return response_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a70a5edd",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading LLM: Qwen/Qwen2.5-3B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--Qwen--Qwen2.5-3B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Downloading shards:  50%|█████     | 1/2 [01:44<01:44, 104.74s/it]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Downloading shards: 100%|██████████| 2/2 [02:41<00:00, 80.89s/it] \n",
      "Loading checkpoint shards: 100%|██████████| 2/2 [00:05<00:00,  2.50s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Loaded successfully.\n",
      "\n",
      "==================================================\n",
      "BẮT ĐẦU QUÁ TRÌNH GENERATE\n",
      "==================================================\n",
      "\n",
      "[1] Messages (List of Dicts):\n",
      "[{'role': 'system', 'content': 'Bạn là nhân viên hỗ trợ đặt món tại nhà hàng Hòa Viên.'}, {'role': 'user', 'content': 'Nhà hàng có món gì ngon?'}]\n",
      "\n",
      "[2] Text sau khi Template (String raw):\n",
      "'<|im_start|>system\\nBạn là nhân viên hỗ trợ đặt món tại nhà hàng Hòa Viên.<|im_end|>\\n<|im_start|>user\\nNhà hàng có món gì ngon?<|im_end|>\\n<|im_start|>assistant\\n'\n",
      "\n",
      "[3] Input Ids (Tensor số hóa câu hỏi):\n",
      "tensor([[151644,   8948,    198,  94917,  37915, 128310,  97483, 129481, 128886,\n",
      "         128845, 129994, 128272, 128275,  61758, 134315,  11401,  27021,     13,\n",
      "         151645,    198, 151644,    872,    198,  79759,   6362,  61758,  28776,\n",
      "         129994, 128382,   7777,    263,     30, 151645,    198, 151644,  77091,\n",
      "            198]], device='cuda:0')\n",
      " -> Kích thước Input: torch.Size([1, 37]) (Dài 37 tokens)\n",
      "\n",
      "[4] Đang suy nghĩ (Generate)...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "The attention mask is not set and cannot be inferred from input because pad token is same as eos token. As a consequence, you may observe unexpected behavior. Please pass your input's `attention_mask` to obtain reliable results.\n",
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\qwen2\\modeling_qwen2.py:544: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " -> Generated Ids Raw (Gồm cả Input + Output):\n",
      "tensor([[151644,   8948,    198,  94917,  37915, 128310,  97483, 129481, 128886,\n",
      "         128845, 129994, 128272, 128275,  61758, 134315,  11401,  27021,     13,\n",
      "         151645,    198, 151644,    872,    198,  79759,   6362,  61758,  28776,\n",
      "         129994, 128382,   7777,    263,     30, 151645,    198, 151644,  77091,\n",
      "            198,     34,  21742, 128275,  61758, 134315,  11401,  27021, 128323,\n",
      "         128907, 130249,  47742,   1319,    644, 140116,  69086,  78228, 129994,\n",
      "         128442,     11,  94576, 129994, 129045, 128573, 128263,  78228, 129994,\n",
      "         128442, 128688,     11, 137790,    489,  92358,  47742, 137790, 129597,\n",
      "             13, 129005,  65526, 129994,   7777,    263, 129144, 132345, 128260,\n",
      "           1447,     16,     13,    386,   3165,    521,    352,     25,    425,\n",
      "         124415, 135570,     11, 132710,    856,   4458,     78,    521,    352,\n",
      "             11, 132710,    296,  23531,    521,    352,   9338,     17,     13,\n",
      "            386,   3165, 134101,     25,    425,  24180,    521,  21742,     11,\n",
      "            293,  24180,  24185, 124634,    272,   4284,     11,    293,  24180,\n",
      "          58701,   9338,     18,     13,    386,   3165, 128788,  85636,     25,\n",
      "            425,  24180,    521,  21742,  58701,     11,    293,  24180,  24185,\n",
      "         124634,    272,   4284,     11,    293,  24180, 140747,    296, 125238,\n",
      "            259,  94365,   9338,     19,     13,    386,   3165, 128442, 128688,\n",
      "             25,    425, 124415,    296,  23531, 138432,     11,    293,  24180,\n",
      "            293,  22190,  21793,  26068,     11,   1319,  78820,   2146,     51,\n",
      "          51358, 125440, 128582,  63478, 128751, 128871, 128250, 129031,  88057,\n",
      "         133683,   7777,    263,  47742, 128328, 128361, 135247, 128501, 128668,\n",
      "             13, 138824, 129994, 128442, 128582,  50196, 133899, 128444, 130008,\n",
      "         128589,  59735, 128275,  61758,     11, 129831, 128319, 128250,  97610,\n",
      "         128444, 128271, 128251,     13, 129096, 129805, 128542, 128457, 129372,\n",
      "         128424,  79668,  63478, 128379, 128580, 128622, 128265, 128336, 128666,\n",
      "         130535,    308,    352, 130236,      0, 151645]], device='cuda:0')\n",
      " -> Kích thước Raw: torch.Size([1, 240]) (Dài 240 tokens)\n",
      "\n",
      "[5] Sliced Ids (Chỉ còn phần trả lời):\n",
      "tensor([    34,  21742, 128275,  61758, 134315,  11401,  27021, 128323, 128907,\n",
      "        130249,  47742,   1319,    644, 140116,  69086,  78228, 129994, 128442,\n",
      "            11,  94576, 129994, 129045, 128573, 128263,  78228, 129994, 128442,\n",
      "        128688,     11, 137790,    489,  92358,  47742, 137790, 129597,     13,\n",
      "        129005,  65526, 129994,   7777,    263, 129144, 132345, 128260,   1447,\n",
      "            16,     13,    386,   3165,    521,    352,     25,    425, 124415,\n",
      "        135570,     11, 132710,    856,   4458,     78,    521,    352,     11,\n",
      "        132710,    296,  23531,    521,    352,   9338,     17,     13,    386,\n",
      "          3165, 134101,     25,    425,  24180,    521,  21742,     11,    293,\n",
      "         24180,  24185, 124634,    272,   4284,     11,    293,  24180,  58701,\n",
      "          9338,     18,     13,    386,   3165, 128788,  85636,     25,    425,\n",
      "         24180,    521,  21742,  58701,     11,    293,  24180,  24185, 124634,\n",
      "           272,   4284,     11,    293,  24180, 140747,    296, 125238,    259,\n",
      "         94365,   9338,     19,     13,    386,   3165, 128442, 128688,     25,\n",
      "           425, 124415,    296,  23531, 138432,     11,    293,  24180,    293,\n",
      "         22190,  21793,  26068,     11,   1319,  78820,   2146,     51,  51358,\n",
      "        125440, 128582,  63478, 128751, 128871, 128250, 129031,  88057, 133683,\n",
      "          7777,    263,  47742, 128328, 128361, 135247, 128501, 128668,     13,\n",
      "        138824, 129994, 128442, 128582,  50196, 133899, 128444, 130008, 128589,\n",
      "         59735, 128275,  61758,     11, 129831, 128319, 128250,  97610, 128444,\n",
      "        128271, 128251,     13, 129096, 129805, 128542, 128457, 129372, 128424,\n",
      "         79668,  63478, 128379, 128580, 128622, 128265, 128336, 128666, 130535,\n",
      "           308,    352, 130236,      0, 151645], device='cuda:0')\n",
      "\n",
      "[6] Kết quả cuối cùng (Decoded Text):\n",
      "Cả nhà hàng Hòa Viên rất đa dạng và phong phú trong các món ăn, từ món truyền thống đến các món ăn sáng, bữa trưa và bữa tối. Một số món ngon nổi bật như:\n",
      "\n",
      "1. Món chay: Bánh cuốn, bánh xèo chay, bánh mì chay...\n",
      "2. Món thịt: Bún chả, bún riêu cua, bún cá...\n",
      "3. Món đặc sản: Bún chả cá, bún riêu cua, bún đậu mắm tôm...\n",
      "4. Món ăn sáng: Bánh mì trứng, bún bò Huế, phở...\n",
      "\n",
      "Tất cả đều được chế biến với nguyên liệu tươi ngon và cách trình bày đẹp mắt. Mỗi món ăn đều mang hương vị riêng biệt của nhà hàng, phù hợp với khẩu vị nhiều người. Bạn hãy liên hệ trực tiếp để được tư vấn thêm về thực đơn hôm nay nhé!\n",
      "\n",
      "==================================================\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'Cả nhà hàng Hòa Viên rất đa dạng và phong phú trong các món ăn, từ món truyền thống đến các món ăn sáng, bữa trưa và bữa tối. Một số món ngon nổi bật như:\\n\\n1. Món chay: Bánh cuốn, bánh xèo chay, bánh mì chay...\\n2. Món thịt: Bún chả, bún riêu cua, bún cá...\\n3. Món đặc sản: Bún chả cá, bún riêu cua, bún đậu mắm tôm...\\n4. Món ăn sáng: Bánh mì trứng, bún bò Huế, phở...\\n\\nTất cả đều được chế biến với nguyên liệu tươi ngon và cách trình bày đẹp mắt. Mỗi món ăn đều mang hương vị riêng biệt của nhà hàng, phù hợp với khẩu vị nhiều người. Bạn hãy liên hệ trực tiếp để được tư vấn thêm về thực đơn hôm nay nhé!'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bot = LLMWrapper()\n",
    "bot.generate(\"Nhà hàng có món gì ngon?\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
