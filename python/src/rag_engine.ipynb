{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a492a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Failed to import transformers.models.auto because of the following error (look up to see its traceback):\nNo module named 'transformers.models'",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\utils\\import_utils.py:1778\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1777\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m-> 1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mimportlib\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mimport_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43m.\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;241;43m+\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mmodule_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;18;43m__name__\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\importlib\\__init__.py:127\u001b[0m, in \u001b[0;36mimport_module\u001b[1;34m(name, package)\u001b[0m\n\u001b[0;32m    126\u001b[0m         level \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m--> 127\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_bootstrap\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_gcd_import\u001b[49m\u001b[43m(\u001b[49m\u001b[43mname\u001b[49m\u001b[43m[\u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m:\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpackage\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlevel\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:961\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:219\u001b[0m, in \u001b[0;36m_call_with_frames_removed\u001b[1;34m(f, *args, **kwds)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1014\u001b[0m, in \u001b[0;36m_gcd_import\u001b[1;34m(name, package, level)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:991\u001b[0m, in \u001b[0;36m_find_and_load\u001b[1;34m(name, import_)\u001b[0m\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:973\u001b[0m, in \u001b[0;36m_find_and_load_unlocked\u001b[1;34m(name, import_)\u001b[0m\n",
      "\u001b[1;31mModuleNotFoundError\u001b[0m: No module named 'transformers.models'",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 2\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mqdrant_client\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m QdrantClient\n\u001b[1;32m----> 2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m SentenceTransformer\n\u001b[0;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mconfig\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m Config\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\__init__.py:10\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mos\u001b[39;00m\n\u001b[0;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbackend\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m export_dynamic_quantized_onnx_model, export_optimized_onnx_model\n\u001b[1;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcross_encoder\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdatasets\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ParallelSentencesDataset, SentencesDataset\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01msentence_transformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mLoggingHandler\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m LoggingHandler\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\cross_encoder\\__init__.py:3\u001b[0m\n\u001b[0;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m__future__\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m annotations\n\u001b[1;32m----> 3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mCrossEncoder\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m CrossEncoder\n\u001b[0;32m      5\u001b[0m __all__ \u001b[38;5;241m=\u001b[39m [\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mCrossEncoder\u001b[39m\u001b[38;5;124m\"\u001b[39m]\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:14\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DataLoader\n\u001b[0;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtqdm\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mautonotebook\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m tqdm, trange\n\u001b[1;32m---> 14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m AutoConfig, AutoModelForSequenceClassification, AutoTokenizer, is_torch_npu_available\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mtokenization_utils_base\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m BatchEncoding\n\u001b[0;32m     16\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01mtransformers\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m PushToHubMixin\n",
      "File \u001b[1;32m<frozen importlib._bootstrap>:1039\u001b[0m, in \u001b[0;36m_handle_fromlist\u001b[1;34m(module, fromlist, import_, recursive)\u001b[0m\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\utils\\import_utils.py:1766\u001b[0m, in \u001b[0;36m_LazyModule.__getattr__\u001b[1;34m(self, name)\u001b[0m\n\u001b[0;32m   1764\u001b[0m     value \u001b[38;5;241m=\u001b[39m Placeholder\n\u001b[0;32m   1765\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_class_to_module\u001b[38;5;241m.\u001b[39mkeys():\n\u001b[1;32m-> 1766\u001b[0m     module \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_get_module\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_class_to_module\u001b[49m\u001b[43m[\u001b[49m\u001b[43mname\u001b[49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m   1767\u001b[0m     value \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mgetattr\u001b[39m(module, name)\n\u001b[0;32m   1768\u001b[0m \u001b[38;5;28;01melif\u001b[39;00m name \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_modules:\n",
      "File \u001b[1;32mc:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\utils\\import_utils.py:1780\u001b[0m, in \u001b[0;36m_LazyModule._get_module\u001b[1;34m(self, module_name)\u001b[0m\n\u001b[0;32m   1778\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m importlib\u001b[38;5;241m.\u001b[39mimport_module(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m module_name, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m)\n\u001b[0;32m   1779\u001b[0m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[1;32m-> 1780\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[0;32m   1781\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to import \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m\u001b[38;5;18m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m.\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mmodule_name\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m because of the following error (look up to see its\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1782\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m traceback):\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;132;01m{\u001b[39;00me\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   1783\u001b[0m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21;01me\u001b[39;00m\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Failed to import transformers.models.auto because of the following error (look up to see its traceback):\nNo module named 'transformers.models'"
     ]
    }
   ],
   "source": [
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from config import Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4a0a0d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class UniMSRAG:\n",
    "    \"\"\"\n",
    "    ƒê√¢y l√† ph·∫ßn c·ªët l√µi th·ª±c hi·ªán logic UniMS-RAG  g·ªìm 3 b∆∞·ªõc:\n",
    "    - Knowledge Source Selection (Planner): Quy·∫øt ƒë·ªãnh c√≥ c·∫ßn t√¨m ki·∫øm th√¥ng tin kh√¥ng.\n",
    "    - Knowledge Retrieval (Retriever): T√¨m ki·∫øm vector.\n",
    "    - Response Generation (Reader): Sinh c√¢u tr·∫£ l·ªùi.\n",
    "    \"\"\"\n",
    "    def __init__(self, llm, qdrant_client):\n",
    "        self.llm = llm\n",
    "        self.client = qdrant_client\n",
    "        self.encoder = SentenceTransformer(Config.EMBEDDING_MODEL)\n",
    "    \n",
    "    def planner(self, user_query):\n",
    "        \"\"\"\n",
    "        Step 1: Knowledge Source Selection [cite: 38, 139]\n",
    "        Quy·∫øt ƒë·ªãnh xem c√¢u h·ªèi c√≥ c·∫ßn tra c·ª©u menu/th√¥ng tin nh√† h√†ng kh√¥ng.\n",
    "        \"\"\"\n",
    "        prompt = (\n",
    "            f\"C√¢u h·ªèi: \\\"{user_query}\\\"\\n\"\n",
    "            \"H√£y x√°c ƒë·ªãnh xem c√¢u h·ªèi n√†y c√≥ c·∫ßn tra c·∫•u th√¥ng tin v·ªÅ menu (gi√°, m√≥n ƒÉn) \"\n",
    "            \"ho·∫∑c th√¥ng tin nh√† h√†ng (ƒë·ªãa ch·ªâ, gi·ªù m·ªü c·ª≠a) kh√¥ng?\\n\"\n",
    "            \"N·∫øu C√ì, h√£y tr·∫£ l·ªùi: [SEARCH]\\n\"\n",
    "            \"N·∫øu KH√îNG (v√≠ d·ª•: ch√†o h·ªèi, c·∫£m ∆°n), h√£y tr·∫£ l·ªùi: [NO_SEARCH]\"\n",
    "        )\n",
    "        response = self.llm.generate(prompt, max_new_tokens=10)\n",
    "        print(\"[1] \" + response)\n",
    "        if \"SEARCH\" in response:\n",
    "            return \"SEARCH\"\n",
    "        return \"NO_SEARCH\"\n",
    "    \n",
    "    def retriever(self, user_query, top_k=3):\n",
    "        \"\"\"\n",
    "        Step 2: Knowledge Retrieval [cite: 40, 141]\n",
    "        T√¨m ki·∫øm c√°c ƒëo·∫°n vƒÉn b·∫£n li√™n quan trong Qdrant.\n",
    "        \"\"\"\n",
    "        query_vector = self.encoder.encode(user_query).tolist()\n",
    "        hits = self.client.search(\n",
    "            collection_name=Config.COLLECTION_NAME,\n",
    "            query_vector=query_vector,\n",
    "            limit=top_k\n",
    "        )\n",
    "        results = [hit.payload['text'] for hit in hits]\n",
    "        print(\"[2] \" + results)\n",
    "        return results\n",
    "    \n",
    "    def reader(self, user_query, retrieved_contexts):\n",
    "        \"\"\"\n",
    "        Step 3: Response Generation [cite: 41, 143]\n",
    "        Sinh c√¢u tr·∫£ l·ªùi d·ª±a tr√™n ng·ªØ c·∫£nh ƒë√£ t√¨m ƒë∆∞·ª£c.\n",
    "        \"\"\"\n",
    "        context_str = \"\\n\".join([f\" - {c}\" for c in retrieved_contexts])\n",
    "        \n",
    "        print(\"[3] \" + context_str)\n",
    "        prompt = (\n",
    "            \"D∆∞·ªõi ƒë√¢y l√† th√¥ng tin t·ª´ c∆° s·ªü d·ªØ li·ªáu c·ªßa nh√† h√†ng H√≤a Vi√™n (Hoa Vien Restaurant):\\n\"\n",
    "            f\"{context_str}\\n\\n\"\n",
    "            \"H√£y ƒë√≥ng vai l√† m·ªôt nh√¢n vi√™n ph·ª•c v·ª• th√¢n thi·ªán, chuy√™n nghi·ªáp c·ªßa nh√† h√†ng H√≤a Vi√™n. \"\n",
    "            \"D·ª±a v√†o th√¥ng tin tr√™n, h√£y tr·∫£ l·ªùi c√¢u h·ªèi c·ªßa kh√°ch h√†ng.\\n\"\n",
    "            f\"Kh√°ch h√†ng: {user_query}\\n\"\n",
    "            \"Tr·∫£ l·ªùi:\"\n",
    "        )\n",
    "        return self.llm.generate(prompt)\n",
    "\n",
    "    def process(self, user_query):\n",
    "        # 1. Plan\n",
    "        action = self.planner(user_query)\n",
    "        \n",
    "        # 2. Retrieve\n",
    "        contexts = []\n",
    "        if action == \"[SEARCH]\":\n",
    "            contexts = self.retriever(user_query)\n",
    "        \n",
    "        # 3. Generate\n",
    "        if contexts:\n",
    "            return self.reader(user_query, contexts)\n",
    "        else:\n",
    "            # N·∫øu kh√¥ng c·∫ßn search, tr·∫£ l·ªùi tr·ª±c ti·∫øp (chitchat)\n",
    "            prompt = (\n",
    "                \"B·∫°n l√† nh√¢n vi√™n nh√† h√†ng H√≤a Vi√™n. \"\n",
    "                f\"Kh√°ch h√†ng n√≥i: \\\"{user_query}\\\". \"\n",
    "                \"H√£y ph·∫£n h·ªìi m·ªôt c√°ch l·ªãch s·ª±, ng·∫Øn g·ªçn.\"\n",
    "            )\n",
    "            return self.llm.generate(prompt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "5e04afdc",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "‚úÖ System Ready!\n",
      "\n",
      "==================================================\n",
      "B·∫ÆT ƒê·∫¶U H·ªéI ƒê√ÅP\n",
      "==================================================\n",
      "\n",
      "üë§ User: Xin ch√†o, b·∫°n kh·ªèe kh√¥ng?\n",
      "[1] [NO_SEARCH]\n",
      "ü§ñ Bot: Xin ch√†o! T√¥i t·ªët l·∫Øm, c·∫£m ∆°n ƒë√£ h·ªèi. B·∫°n c·∫ßn t√¥i gi√∫p g√¨ h√¥m nay kh√¥ng?\n",
      "\n",
      "üë§ User: Gi√° l·∫©u cua ƒë·ªìng l√† bao nhi√™u?\n",
      "[1] [SEARCH]\n",
      "ü§ñ Bot: Ch√†o qu√Ω kh√°ch, gi√° l·∫©u cua ƒë·ªìng c·ªßa ch√∫ng t√¥i hi·ªán t·∫°i l√† 150.000ƒë cho m·ªôt su·∫•t. Mong qu√Ω kh√°ch s·∫Ω ·ªßng h·ªô nh√† h√†ng c·ªßa ch√∫ng t√¥i.\n",
      "\n",
      "üë§ User: Nh√† h√†ng m·ªü c·ª≠a l√∫c m·∫•y gi·ªù?\n",
      "[1] [NO_SEARCH]\n",
      "ü§ñ Bot: Ch√†o qu√Ω kh√°ch, nh√† h√†ng c·ªßa ch√∫ng t√¥i b·∫Øt ƒë·∫ßu ph·ª•c v·ª• t·ª´ 11:00 ƒë·∫øn 22:00 m·ªói ng√†y. Xin c·∫£m ∆°n!\n",
      "\n",
      "üë§ User: T√¥i mu·ªën ƒÉn g√¨ ƒë√≥ cay cay\n",
      "[1] [NO_SEARCH]\n",
      "ü§ñ Bot: Ch·∫Øc ch·∫Øn, ch√∫ng t√¥i c√≥ nhi·ªÅu m√≥n ngon v·ªõi v·ªã cay cay nh∆∞ c√°c m√≥n g·ªèi, nem r√°n hay c√°c lo·∫°i m√¨ ƒë·∫∑c bi·ªát. B·∫°n mu·ªën th·ª≠ m√≥n n√†o ngay b√¢y gi·ªù kh√¥ng?\n",
      "\n",
      "üë§ User: ∆† ƒë√¢y c√≥ b√°n m√≥n g√¨ 50000 kh√¥ng\n",
      "[1] [SEARCH]\n",
      "ü§ñ Bot: Xin l·ªói ƒë√£ v∆∞·ªõng ph·∫£i s·ª± hi·ªÉu l·∫ßm, ch√∫ng t√¥i hi·ªán ƒëang ph·ª•c v·ª• c√°c m√≥n v·ªõi m·ª©c gi√° t·ª´ 30,000 ƒë·∫øn 60,000 VND. Mong qu√Ω kh√°ch th√¥ng c·∫£m.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# B5: Init Chatbot\n",
    "bot = UniMSRAG(llm, client)\n",
    "print(\"\\n‚úÖ System Ready!\")\n",
    "\n",
    "# --- TEST CASE ---\n",
    "queries = [\n",
    "    \"Gi√° l·∫©u cua ƒë·ªìng l√† bao nhi√™u?\", # Case 2: C·∫ßn search Menu\n",
    "    \"Gi√° H√° c·∫£o b√°ch hoa l√† bao nhi√™u?\", # Case 2: C·∫ßn search Menu\n",
    "    \"Nh√† h√†ng m·ªü c·ª≠a l√∫c m·∫•y gi·ªù?\",\n",
    "    \"T√¥i mu·ªën ƒÉn m√≥n g√¨ ƒë√≥ cay cay\",\n",
    "    \"T√¥i mu·ªën ƒÉn g√¨ ƒë√≥ cay cay\",\n",
    "    \"C√≥ nh·ªØng m√≥n n√†o trong menu?\",\n",
    "    \"T√¥i ƒë√£ ƒë·∫∑t nh·ªØng m√≥n g√¨?\",\n",
    "    \"∆† ƒë√¢y c√≥ b√°n m√≥n g√¨ 50000 kh√¥ng\"\n",
    "    \"Xin ch√†o, b·∫°n kh·ªèe kh√¥ng?\",\n",
    "]\n",
    "\n",
    "print(\"\\n\" + \"=\"*50)\n",
    "print(\"B·∫ÆT ƒê·∫¶U H·ªéI ƒê√ÅP\")\n",
    "print(\"=\"*50)\n",
    "\n",
    "for q in queries:\n",
    "    print(f\"\\nüë§ User: {q}\")\n",
    "    try:\n",
    "        response = bot.process(q)\n",
    "        print(f\"ü§ñ Bot: {response}\")\n",
    "    except Exception as e:\n",
    "        print(f\"‚ùå Error: {e}\")\n",
    "        import traceback\n",
    "        traceback.print_exc()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54db3b04",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\sentence_transformers\\cross_encoder\\CrossEncoder.py:13: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from tqdm.autonotebook import tqdm, trange\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================================\n",
      "STARTING FULL SYSTEM TEST\n",
      "==================================================\n",
      "\n",
      "[1/4] Connecting to Qdrant...\n",
      "\n",
      "[2/4] Ingesting Data...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--AITeamVN--Vietnamese_Embedding. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- B·∫Øt ƒë·∫ßu n·∫°p d·ªØ li·ªáu v√†o Vector DB ---\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\transformers\\models\\xlm_roberta\\modeling_xlm_roberta.py:371: UserWarning: 1Torch was not compiled with flash attention. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\builder\\windows\\pytorch\\aten\\src\\ATen\\native\\transformers\\cuda\\sdp_utils.cpp:455.)\n",
      "  attn_output = torch.nn.functional.scaled_dot_product_attention(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "--- ƒê√£ n·∫°p 30 documents v√†o Qdrant ---\n",
      "\n",
      "[3/4] Loading LLM (Wait for model loading)...\n",
      "Loading LLM: Qwen/Qwen2.5-3B-Instruct...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\HP\\AppData\\Local\\Programs\\Python\\Python38\\lib\\site-packages\\huggingface_hub\\file_download.py:143: UserWarning: `huggingface_hub` cache-system uses symlinks by default to efficiently store duplicated files but your machine does not support them in C:\\Users\\HP\\.cache\\huggingface\\hub\\models--Qwen--Qwen2.5-3B-Instruct. Caching files will still work but in a degraded version that might require more space on your disk. This warning can be disabled by setting the `HF_HUB_DISABLE_SYMLINKS_WARNING` environment variable. For more details, see https://huggingface.co/docs/huggingface_hub/how-to-cache#limitations.\n",
      "To support symlinks on Windows, you either need to activate Developer Mode or to run Python as an administrator. In order to activate developer mode, see this article: https://docs.microsoft.com/en-us/windows/apps/get-started/enable-your-device-for-development\n",
      "  warnings.warn(message)\n",
      "Downloading shards:   0%|          | 0/2 [00:00<?, ?it/s]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Downloading shards:  50%|‚ñà‚ñà‚ñà‚ñà‚ñà     | 1/2 [01:57<01:57, 117.96s/it]Xet Storage is enabled for this repo, but the 'hf_xet' package is not installed. Falling back to regular HTTP download. For better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\n",
      "Downloading shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [03:02<00:00, 91.13s/it] \n",
      "Loading checkpoint shards: 100%|‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà‚ñà| 2/2 [00:03<00:00,  1.56s/it]\n",
      "Some parameters are on the meta device because they were offloaded to the cpu.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "LLM Loaded successfully.\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'UniMSRAG' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 25\u001b[0m\n\u001b[0;32m     22\u001b[0m llm \u001b[38;5;241m=\u001b[39m LLMWrapper() \u001b[38;5;66;03m# Class n√†y c·ªßa b·∫°n s·∫Ω t·ª± load Qwen v√† tokenizer\u001b[39;00m\n\u001b[0;32m     24\u001b[0m \u001b[38;5;66;03m# B5: Init Chatbot\u001b[39;00m\n\u001b[1;32m---> 25\u001b[0m bot \u001b[38;5;241m=\u001b[39m \u001b[43mUniMSRAG\u001b[49m(llm, client)\n\u001b[0;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m‚úÖ System Ready!\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m     28\u001b[0m \u001b[38;5;66;03m# --- TEST CASE ---\u001b[39;00m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'UniMSRAG' is not defined"
     ]
    }
   ],
   "source": [
    "from ingest import DataIngestor\n",
    "from llm_wrapper import LLMWrapper\n",
    "from qdrant_client import QdrantClient\n",
    "from sentence_transformers import SentenceTransformer\n",
    "\n",
    "print(\"=\"*50)\n",
    "print(\"STARTING FULL SYSTEM TEST\")\n",
    "print(\"=\"*50)\n",
    "# B2: Kh·ªüi t·∫°o Qdrant (Memory Mode)\n",
    "\n",
    "# V√¨ config ƒë·ªÉ \":memory:\", t·∫Øt code ƒëi l√† m·∫•t d·ªØ li·ªáu -> Ph·∫£i ingest l·∫°i m·ªói l·∫ßn ch·∫°y\n",
    "print(\"\\n[1/4] Connecting to Qdrant...\")\n",
    "client = QdrantClient(location=\":memory:\")\n",
    "\n",
    "# B3: Ingest Data (N·∫°p d·ªØ li·ªáu v√†o RAM)\n",
    "print(\"\\n[2/4] Ingesting Data...\")\n",
    "ingestor = DataIngestor(client)\n",
    "ingestor.ingest()\n",
    "    \n",
    "# B4: Load LLM\n",
    "print(\"\\n[3/4] Loading LLM (Wait for model loading)...\")\n",
    "llm = LLMWrapper() # Class n√†y c·ªßa b·∫°n s·∫Ω t·ª± load Qwen v√† tokenizer\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
